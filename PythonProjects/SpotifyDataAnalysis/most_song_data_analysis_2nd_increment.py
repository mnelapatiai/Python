# -*- coding: utf-8 -*-
"""most_song_data_analysis_2nd_Increment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-JW4BGEU7furbM6kPACc8fB8dVmVHf1Z

# MOST STREAMED SPOTIFY SONG ANALYSIS USING MACHINE LEARNING ALGORITHMS
"""

# Import the 'warnings' module to manage warnings in the code
import warnings
# Ignore all warnings to prevent them from being displayed during code execution
warnings.filterwarnings('ignore')
# Import the required libraries for data analysis and visualization
import numpy as np
import pandas as pd
import matplotlib
import plotly.express as px
import matplotlib.pyplot as plt
import seaborn as sns
# Import the 'StandardScaler' class from the'sklearn.preprocessing' module
from sklearn.preprocessing import StandardScaler

"""# Data Loading & Extraction"""

# Open the "spotify-2023.csv" CSV file and read it into the Pandas DataFrame ('df_sportify').
# To address character encoding issues, specify the encoding as "cp775".
df_sportify = pd.read_csv("spotify-2023.csv", encoding = "cp775")

# To quickly examine the data, show the first 5 rows of the DataFrame "df_sportify."
df_sportify.head(5)

# To quickly examine the data, show the last 5 rows of the DataFrame "df_sportify."
df_sportify.tail(5)

"""# Data Pre-Processing"""

# Display the count of unique values in the 'artist_count' column
df_sportify['artist_count'].value_counts()

# Display the count of unique values in the 'released_year' column
df_sportify['released_year'].value_counts()

# Display the count of unique values in the 'released_month' column
df_sportify['released_month'].value_counts()

# Display the count of unique values in the 'released_day' column
df_sportify['released_day'].value_counts()

# Display the count of unique values in the 'in_spotify_playlists' column
df_sportify['in_spotify_playlists'].value_counts()

# Display the count of unique values in the 'in_spotify_charts' column
df_sportify['in_spotify_charts'].value_counts()

# Display the count of unique values in the 'streams' column
df_sportify['streams'].value_counts()

# Display the count of unique values in the 'danceability_%' column
df_sportify['danceability_%'].value_counts()

# Display the count of unique values in the 'speechiness_%' column
df_sportify['speechiness_%'].value_counts()

# Provide a succinct overview of the DataFrame 'df_sportify'. This covers memory usage, non-null counts, and data types.
df_sportify.info()

# This helps determine the existence and amount of missing data in the dataset by checking and displaying the sum of the missing values in each column of the DataFrame "df_sportify."
df_sportify.isnull().sum()

"""# Data Visualization"""

#Sort the DataFrame 'df_sportify' according to the 'key' column, then count how many times each group's 'in_spotify_playlists' appears.
count_sportify_play = df_sportify.groupby('key')['in_spotify_playlists'].count().reset_index()
# Use Plotly Express to create a bar plot that displays the total number of playlists according to the song keys.
plot1 = px.bar(count_sportify_play, x='key', y='in_spotify_playlists', title='Total playlist with respect to key of the songs', color='key')
# Use the previously defined Plotly Express object 'plot1' to display the generated plot.
plot1.show()

#Group the'mode' column of the DataFrame 'df_sportify', then add up the 'in_spotify_playlists' for every group.
sum_sportify_play = df_sportify.groupby('mode')['in_spotify_playlists'].sum().reset_index()
# Use Plotly Express to create a pie chart that displays the total number of playlists in relation to the song mode.
plot2 = px.pie(sum_sportify_play, values='in_spotify_playlists', names='mode', title='Total paylist with respect to mode')
# Display the pie chart
plot2.show()

# Compute the total of 'danceability_%' for each year by grouping the DataFrame 'df_sportify' by the'released_year' column.
#Using Plotly Express, create an area plot that shows the total amount of danceability relative to the year that the songs were released.
sum_dancebility = df_sportify.groupby('released_year')['danceability_%'].sum().reset_index()
plot3 = px.area(sum_dancebility, x='released_year', y='danceability_%', title='Total sum of the danceability of song with respect to year')
plot3.show()

#To find the total of'speechiness_%' for each key, group the DataFrame 'df_sportify' by the 'key' column.
# Using Plotly Express, create an area plot that shows the total sum of the speechiness percentage in relation to the song key.
sum_speechiness = df_sportify.groupby('key')['speechiness_%'].sum().reset_index()
plot4 = px.area(sum_speechiness, x='key', y='speechiness_%', title='Total sum of the speechiness percentage song with respect to key')
plot4.show()

# Count the instances of'streams' for each key by grouping the DataFrame 'df_sportify' by the 'key' column.
# 'Most Stream analysis': use Plotly Express to create a pie chart that shows the distribution of streams among various keys.
sum_sportify_stream = df_sportify.groupby('key')['streams'].count().reset_index()
plot5 = px.pie(sum_sportify_stream, values='streams', names='key', title='Most Stream analysis')
plot5.show()

# Group the DataFrame 'df_sportify' by the 'mode' column and count the occurrences of 'streams' for each mode.
# Create a pie chart using Plotly Express, displaying the distribution of streams among different modes in a 'Most stream by mode' analysis.
sum_sportify_stream1 = df_sportify.groupby('mode')['streams'].count().reset_index()
plot6 = px.pie(sum_sportify_stream1, values='streams', names='mode', hole=0.6, title='Most stream by mode')
plot6.show()

# Take specific columns out of the DataFrame 'df_sportify': 'artist(s)_name, track_name, in_deezer_playlists, in_shazam_charts, key'.
# Columns are dropped when the 'axis=1' parameter is used, and changes are applied directly to the original DataFrame when the 'inplace=True' option is selected.
df_sportify.drop(['artist(s)_name','track_name', 'in_deezer_playlists', 'in_shazam_charts', 'key'], axis=1, inplace=True)

# After removing certain columns, show the first few rows of the updated DataFrame "df_sportify"
df_sportify.head()

# Show a brief summary of the updated DataFrame "df_sportify" # Data types, non-null counts, and memory usage following column removal are all included in this.
df_sportify.info()

# Convert the values in DataFrame 'df_sportify's'mode' column to binary representation:
#'Major' corresponds to 1 and 'Minor' to 0.
df_sportify['mode'] = df_sportify['mode'].map({'Major': 1, 'Minor': 0})

#Present a brief description of the DataFrame 'df_sportify' following the application of binary representation to the'mode' column.
df_sportify.info()

# To evaluate the effects of earlier changes, check and show the total of missing values in each column of the DataFrame "df_sportify" .
df_sportify.isnull().sum()

"""# Random Forest Classifier"""

# Import the Scikit-Learn modules required for RandomForestClassifier.
# Import functions to divide the dataset and assess the performance of the model
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# For modeling, keep the target variable (y) and the features (X) apart.
# Y contains the'mode' column, which represents the target variable, while
# X contains all other columns.
X = df_sportify.drop('mode', axis=1)
y = df_sportify['mode']

# Use train_test_split to divide the dataset into training and testing sets.
# X_train and y_train stand for the training features and target variable, and X_test and y_test for the testing features and variable.
# For reproducibility, a random seed (random_state=42) is utilized, and the test set size is set to 20%.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

rf_y_pred = rf_model.predict(X_test)

accuracy_rf = accuracy_score(y_test, rf_y_pred)
print('Accuracy of  RandomForestClassifier is ', round(accuracy_rf,2))

rf_report = classification_report(y_test, rf_y_pred)

print('Classification Report:\n', rf_report)

"""# Linear Regression"""

# Import the Scikit-Learn modules required for LinearRegression.
from sklearn.linear_model import LinearRegression

# Creating X and y
X = df_sportify['released_month']
y = df_sportify['streams']

#Splitting the variables as training and testing
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)

# Reshaping the train set without adding a new column
X_train_reshaped = X_train.values.reshape(-1, 1)
X_test_reshaped = X_test.values.reshape(-1, 1)

# Creating an instance of the Linear Regression model
linear_model = LinearRegression()

# Fitting the model using the .fit() method
linear_model.fit(X_train_reshaped, y_train)

# Displaying the intercept value
print("Intercept Value:", linear_model.intercept_)

# Displaying the slope value
print('Slope Value:', linear_model.coef_[0])

# Generating predictions for y_values
predicted_y_train = linear_model.predict(X_train_reshaped)
predicted_y_test = linear_model.predict(X_test_reshaped)

#Calculating the R-squared value
r_squared = r2_score(y_test, predicted_y_test)
print("R-squared:", r_squared)

# Comparing the R-squared values for both the training and testing datasets
print("R-squared on Train Data:", r2_score(y_train, predicted_y_train))
print("R-squared on Test Data:", r2_score(y_test, predicted_y_test))

# Generate predictions on the test dataset
predicted_y = linear_model.predict(X_test_reshaped)

# Assess the model performance using regression metrics
mse = mean_squared_error(y_test, predicted_y)
mae = mean_absolute_error(y_test, predicted_y)

print("Mean Squared Error:", mse)
print("Mean Absolute Error:", mae)

"""# DecisionTreeClassifier"""

# Import the Scikit-Learn modules required for DecisionTreeClassifier.
from sklearn.tree import DecisionTreeClassifier

X = df_sportify.drop('mode', axis=1)  # Features
y = df_sportify['mode']  # Target variable
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

#Establish a decision tree classifier
classifier_model = DecisionTreeClassifier()

#Train the model using the training dataset
classifier_model.fit(X_train, y_train)

# Generate predictions on the test dataset
predicted_y_test = classifier_model.predict(X_test)

# Calculate training accuracy
training_accuracy = accuracy_score(y_train, classifier_model.predict(X_train))

# Compute test accuracy
testing_accuracy = accuracy_score(y_test, predicted_y_test)

# Assess validation accuracy
validation_accuracy = accuracy_score(y_val, classifier_model.predict(X_val))

# Compute cross-validation score
cross_validation_score = cross_val_score(classifier_model, X, y, cv=5).mean()

# Display the results
print("Train Accuracy:", training_accuracy)
print("Test Accuracy:", testing_accuracy)
print("Validation Accuracy:", validation_accuracy)
print("Cross-Validation Score:", cross_validation_score)

# Create a classification report
classification_report_result = classification_report(y_test, predicted_y_test, output_dict=True)

# Convert the classification report dictionary into a DataFrame
classification_report_dataframe = pd.DataFrame(classification_report_result).transpose()

# Display the Classification Report DataFrame
print("\nClassification Report:")
print(classification_report_dataframe)

#Display the Confusion Matrix
print("\nConfusion Matrix:")
sns.heatmap(confusion_matrix(y_test, predicted_y_test), annot=True, cmap='summer')