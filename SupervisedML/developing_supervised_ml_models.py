# -*- coding: utf-8 -*-
"""Developing_supervised_ML_Models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ukNpDrCx9JamyKu6EKci9j0JMCJoi_yT
"""

import pandas as pd

def read_dataset(file_path):
    # Read the dataset into a DataFrame
    df = pd.read_csv(file_path, delimiter='\t', header=None)
    # Check if the DataFrame has the expected number of columns
    if len(df.columns) == 4:
        # Set column names
        df.columns = ['Time', 'Speed', 'RPM', 'Attack']
    else:
        print("Unexpected number of columns in the dataset.")
    # Return the DataFrame
    return df

# Load the dataset
df_speed_injection = read_dataset("/content/CAN Bus log - injection of FFF as the speed reading.log")
print(df_speed_injection.head())

# Load the dataset
df_rpm_injection = read_dataset("/content/CAN Bus log - injection of RPM readings.log")
print(df_rpm_injection.head())

# Load the dataset
df_no_injection = read_dataset("/content/CAN bus log - no injection of messages.log")
print(df_no_injection.head())

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Create a mock DataFrame with sample data for demonstration purposes
np.random.seed(0)  # Ensure reproducibility
time_points = np.arange(0, 1000)  # Simulate 1000 time points
speed_data = np.random.normal(60, 10, 1000)  # Generate speed readings with mean 60 and some noise
rpm_data = np.random.normal(3000, 500, 1000)  # Generate RPM readings with mean 3000 and some noise

# Create DataFrames for speed and RPM readings
df_speed = pd.DataFrame({'can_id': 254, 'value': speed_data}, index=time_points)
df_rpm = pd.DataFrame({'can_id': 115, 'value': rpm_data}, index=time_points)

# Combine the DataFrames into one
df_combined = pd.concat([df_speed, df_rpm])

# Filter the combined DataFrame to get speed and RPM data separately
speed_readings = df_combined[df_combined['can_id'] == 254]
rpm_readings = df_combined[df_combined['can_id'] == 115]

# Plotting the data
plt.figure(figsize=(12, 4))

# Speed over time plot
plt.subplot(1, 3, 1)
plt.scatter(speed_readings.index, speed_readings['value'], alpha=0.6, color='blue')
plt.title('Speed Over Time')
plt.xlabel('Time')
plt.ylabel('Speed')

# RPM over time plot
plt.subplot(1, 3, 2)
plt.scatter(rpm_readings.index, rpm_readings['value'], alpha=0.6, color='green')
plt.title('RPM Over Time')
plt.xlabel('Time')
plt.ylabel('RPM')

# Speed vs RPM plot
plt.subplot(1, 3, 3)
plt.scatter(speed_readings['value'], rpm_readings['value'], alpha=0.6, color='purple')
plt.title('Speed vs RPM')
plt.xlabel('Speed')
plt.ylabel('RPM')

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Set seed for reproducibility
np.random.seed(0)

# Generate synthetic speed data (mean = 50, std = 10)
speed_data = np.random.normal(50, 10, 1000)

# Generate synthetic RPM data (mean = 3000, std = 500)
rpm_data = np.random.normal(3000, 500, 1000)

# Create subplots for frequency plots
fig, axs = plt.subplots(1, 2, figsize=(14, 6))

# Plot frequency distribution of speed data
axs[0].hist(speed_data, bins=30, color='red', edgecolor='black')
axs[0].set_title('Frequency Distribution of Speed')
axs[0].set_xlabel('Speed (km/h)')
axs[0].set_ylabel('Frequency')

# Plot frequency distribution of RPM data
axs[1].hist(rpm_data, bins=30, color='lightgreen', edgecolor='black')
axs[1].set_title('Frequency Distribution of RPM')
axs[1].set_xlabel('RPM')
axs[1].set_ylabel('Frequency')

# Adjust layout to prevent overlap
plt.tight_layout()
plt.show()

from scipy.stats import pearsonr

# Calculating Pearson Correlation and associated P-value between Speed and RPM readings
corr_coefficient, p_value = pearsonr(speed_data, rpm_data)

# Displaying the results in a table format
from tabulate import tabulate

# Creating a table with the results
table = [['Correlation Coefficient', 'P-value'], [corr_coefficient, p_value]]
print(tabulate(table, headers='firstrow', tablefmt='grid'))

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report

# Generate synthetic data
np.random.seed(0)
speed_data = np.random.normal(50, 10, 1000)
rpm_data = np.random.normal(3000, 500, 1000)
attack_labels = np.random.choice([0, 1], size=1000, p=[0.7, 0.3])

# Combine the data into a single dataset
dataset = np.column_stack((speed_data, rpm_data, attack_labels))

# Define features and target variable
X = dataset[:, :2]  # Features: speed and RPM
y = dataset[:, 2]   # Target: attack labels

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Initialize and train the Random Forest Classifier
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = rf_classifier.predict(X_test)

# Evaluate the model
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

print("Confusion Matrix:")
print(conf_matrix)
print("\nClassification Report:")
print(class_report)

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, classification_report

# Generate synthetic data
np.random.seed(0)
speed_data = np.random.normal(50, 10, 1000)
rpm_data = np.random.normal(3000, 500, 1000)
attack_labels = np.random.choice([0, 1], size=1000, p=[0.7, 0.3])

# Combine the data into a single dataset
dataset = np.column_stack((speed_data, rpm_data, attack_labels))

# Define features and target variable
X = dataset[:, :2]  # Features: speed and RPM
y = dataset[:, 2]   # Target: attack labels

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Initialize and train the Decision Tree Classifier
dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = dt_classifier.predict(X_test)

# Evaluate the model
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

print("Confusion Matrix:")
print(conf_matrix)
print("\nClassification Report:")
print(class_report)

